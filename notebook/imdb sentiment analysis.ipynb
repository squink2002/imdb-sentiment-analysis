{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDb Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing relevant libraries:\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from string import punctuation\n",
    "\n",
    "# Sci-Kit Learn:\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# NLTK:\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.stem import LancasterStemmer, WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the IMDb data\n",
    "imdb = pd.read_csv(r\"C:\\Users\\sando\\OneDrive\\Escritorio\\Personal Projects\\IMDB Sentiment Analysis\\dataset\\imdb_reviews.csv\", encoding = 'UTF-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review     50000 non-null  object\n",
      " 1   sentiment  50000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 781.4+ KB\n"
     ]
    }
   ],
   "source": [
    "imdb.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the columsn to string\n",
    "imdb['review'] = imdb['review'].astype(str)\n",
    "imdb['sentiment'] = imdb['sentiment'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "positive    25000\n",
       "negative    25000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking if our data is balanced\n",
    "imdb['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset using sklearn\n",
    "X = imdb['review'] # features\n",
    "y = imdb['sentiment'] # target labels\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size= 0.3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review\n",
       "False    50000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for NAN values:\n",
    "imdb['review'].isna().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing HTML Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the html strips:\n",
    "def strip_html_tags(text):\n",
    "    soup = BeautifulSoup(text, 'html.parser')\n",
    "    return soup.get_text()\n",
    "\n",
    "# # Applying our function:\n",
    "# imdb['review'] = imdb['review'].apply(strip_html_tags)\n",
    "# imdb['review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "\n",
    "# Cleaning up the text:\n",
    "def clean_text(text):\n",
    "    # Tokenizing the text\n",
    "    words = word_tokenize(text)\n",
    "    # Removing stop words, punctuation, and numbers \n",
    "    processed_words = [w for w in words if w.lower() not in stop_words and w not in punctuation and not w.isdigit()]\n",
    "    processed_words = ' '.join(processed_words)\n",
    "    return processed_words \n",
    "\n",
    "# imdb['review'] = imdb['review'].apply(clean_text)\n",
    "# print(imdb['review']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing Special Charcaters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing special characters:\n",
    "def remove_special_characters(text, remove_digits = False):\n",
    "    pattern = r'[^a-zA-Z0-9\\s]' if not remove_digits else r'[a-zA-Z\\s]'\n",
    "    text = re.sub(pattern, '', text)\n",
    "    return text\n",
    "\n",
    "# imdb['review'] = imdb['review'].apply(remove_special_characters) \n",
    "# imdb['review']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing Redundant Whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the redundant whitespaces:\n",
    "def remove_redundant_whitespaces(text):\n",
    "    text = re.sub(pattern= r'\\s+', repl= ' ', string= text)\n",
    "    return text.strip()\n",
    "\n",
    "# imdb['review'] = imdb['review'].apply(remove_redundant_whitespaces)\n",
    "# print(imdb['review'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "source": [
    "# Text Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemming the text:\n",
    "def simple_stemmer(text):\n",
    "    stemmer = PorterStemmer()\n",
    "    words = text.split()\n",
    "    stemmed_text = ' '.join([stemmer.stem(word) for word in words])\n",
    "    return stemmed_text\n",
    "\n",
    "# imdb['review'] = imdb['review'].apply(simple_stemmer)\n",
    "# print(imdb['review'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining Things Together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        one review mention watch oz episod hook right ...\n",
      "1        wonder littl product film techniqu unassum old...\n",
      "2        thought wonder way spend time hot summer weeke...\n",
      "3        basic famili littl boy jake think zombi closet...\n",
      "4        petter mattei love time money visual stun film...\n",
      "                               ...                        \n",
      "49995    thought movi right good job nt creativ origin ...\n",
      "49996    bad plot bad dialogu bad act idiot direct anno...\n",
      "49997    cathol taught parochi elementari school nun ta...\n",
      "49998    go disagr previou comment side maltin one seco...\n",
      "49999    one expect star trek movi high art fan expect ...\n",
      "Name: review, Length: 50000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def normalize_text(text):\n",
    "    # Removing the HTML tags:\n",
    "    normalized_text = strip_html_tags(text)\n",
    "\n",
    "    # Removing stop words, punctuation, and numbers\n",
    "    normalized_text = clean_text(normalized_text)\n",
    "\n",
    "    # Removing special characters:\n",
    "    normalized_text = remove_special_characters(normalized_text, remove_digits = False)\n",
    "\n",
    "    # Removing the redundant whitespaces:\n",
    "    normalized_text = remove_redundant_whitespaces(normalized_text)\n",
    "\n",
    "    # Stemmatization:\n",
    "    normalized_text = simple_stemmer(normalized_text)\n",
    "    \n",
    "    return normalized_text\n",
    "\n",
    "imdb['review'] = imdb['review'].apply(normalize_text)\n",
    "print(imdb['review'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(min_df= 0, max_df= 1, binary= False, ngram_range= (1,3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
