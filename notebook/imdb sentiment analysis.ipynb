{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDb Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing relevant libraries:\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import re, string, unicodedata\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.stem import LancasterStemmer,WordNetLemmatizer\n",
    "\n",
    "from textblob import TextBlob\n",
    "from textblob import Word\n",
    "\n",
    "from wordcloud import WordCloud,STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the IMDb data\n",
    "\n",
    "imdb = pd.read_csv(r\"C:\\Users\\sando\\OneDrive\\Escritorio\\Personal Projects\\IMDB Sentiment Analysis\\dataset\\imdb_reviews.csv\", encoding = 'UTF-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review     50000 non-null  object\n",
      " 1   sentiment  50000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 781.4+ KB\n"
     ]
    }
   ],
   "source": [
    "imdb.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the columsn to string\n",
    "imdb['review'] = imdb['review'].astype(str)\n",
    "imdb['sentiment'] = imdb['sentiment'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "positive    25000\n",
       "negative    25000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking if our data is balanced\n",
    "imdb['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset using sklearn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = imdb['review'] # features\n",
    "y = imdb['sentiment'] # target labels\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size= 0.3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review\n",
       "False    50000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for NAN values:\n",
    "\n",
    "imdb['review'].isna().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing HTML Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sando\\AppData\\Local\\Temp\\ipykernel_15532\\3219507399.py:3: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup = BeautifulSoup(text, 'html.parser')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0        One of the other reviewers has mentioned that ...\n",
       "1        A wonderful little production. The filming tec...\n",
       "2        I thought this was a wonderful way to spend ti...\n",
       "3        Basically there's a family where a little boy ...\n",
       "4        Petter Mattei's \"Love in the Time of Money\" is...\n",
       "                               ...                        \n",
       "49995    I thought this movie did a down right good job...\n",
       "49996    Bad plot, bad dialogue, bad acting, idiotic di...\n",
       "49997    I am a Catholic taught in parochial elementary...\n",
       "49998    I'm going to have to disagree with the previou...\n",
       "49999    No one expects the Star Trek movies to be high...\n",
       "Name: review, Length: 50000, dtype: object"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing the html strips:\n",
    "def strip_html_tags(text):\n",
    "    soup = BeautifulSoup(text, 'html.parser')\n",
    "    return soup.get_text()\n",
    "\n",
    "# Applying our function:\n",
    "imdb['review'] = imdb['review'].apply(strip_html_tags)\n",
    "imdb['review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        [One, reviewers, mentioned, watching, Oz, epis...\n",
      "1        [wonderful, little, production, filming, techn...\n",
      "2        [thought, wonderful, way, spend, time, hot, su...\n",
      "3        [Basically, 's, family, little, boy, Jake, thi...\n",
      "4        [Petter, Mattei, 's, ``, Love, Time, Money, ''...\n",
      "                               ...                        \n",
      "49995    [thought, movie, right, good, job, n't, creati...\n",
      "49996    [Bad, plot, bad, dialogue, bad, acting, idioti...\n",
      "49997    [Catholic, taught, parochial, elementary, scho...\n",
      "49998    ['m, going, disagree, previous, comment, side,...\n",
      "49999    [one, expects, Star, Trek, movies, high, art, ...\n",
      "Name: review, Length: 50000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "# Cleaning up the text:\n",
    "def clean_text(text):\n",
    "    # Tokenizing the text\n",
    "    words = word_tokenize(text)\n",
    "    # Removing stop words, punctuation, and numbers \n",
    "    processed_words = [w for w in words if w.lower() not in stop_words and w not in punctuation and not w.isdigit()]\n",
    "    return processed_words \n",
    "\n",
    "imdb['review'] = imdb['review'].apply(tokenize_text)\n",
    "print(imdb['review']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['One',\n",
       " 'reviewers',\n",
       " 'mentioned',\n",
       " 'watching',\n",
       " 'Oz',\n",
       " 'episode',\n",
       " \"'ll\",\n",
       " 'hooked',\n",
       " 'right',\n",
       " 'exactly',\n",
       " 'happened',\n",
       " 'me.The',\n",
       " 'first',\n",
       " 'thing',\n",
       " 'struck',\n",
       " 'Oz',\n",
       " 'brutality',\n",
       " 'unflinching',\n",
       " 'scenes',\n",
       " 'violence',\n",
       " 'set',\n",
       " 'right',\n",
       " 'word',\n",
       " 'GO',\n",
       " 'Trust',\n",
       " 'show',\n",
       " 'faint',\n",
       " 'hearted',\n",
       " 'timid',\n",
       " 'show',\n",
       " 'pulls',\n",
       " 'punches',\n",
       " 'regards',\n",
       " 'drugs',\n",
       " 'sex',\n",
       " 'violence',\n",
       " 'hardcore',\n",
       " 'classic',\n",
       " 'use',\n",
       " 'word.It',\n",
       " 'called',\n",
       " 'OZ',\n",
       " 'nickname',\n",
       " 'given',\n",
       " 'Oswald',\n",
       " 'Maximum',\n",
       " 'Security',\n",
       " 'State',\n",
       " 'Penitentary',\n",
       " 'focuses',\n",
       " 'mainly',\n",
       " 'Emerald',\n",
       " 'City',\n",
       " 'experimental',\n",
       " 'section',\n",
       " 'prison',\n",
       " 'cells',\n",
       " 'glass',\n",
       " 'fronts',\n",
       " 'face',\n",
       " 'inwards',\n",
       " 'privacy',\n",
       " 'high',\n",
       " 'agenda',\n",
       " 'Em',\n",
       " 'City',\n",
       " 'home',\n",
       " 'many',\n",
       " '..',\n",
       " 'Aryans',\n",
       " 'Muslims',\n",
       " 'gangstas',\n",
       " 'Latinos',\n",
       " 'Christians',\n",
       " 'Italians',\n",
       " 'Irish',\n",
       " '....',\n",
       " 'scuffles',\n",
       " 'death',\n",
       " 'stares',\n",
       " 'dodgy',\n",
       " 'dealings',\n",
       " 'shady',\n",
       " 'agreements',\n",
       " 'never',\n",
       " 'far',\n",
       " 'away.I',\n",
       " 'would',\n",
       " 'say',\n",
       " 'main',\n",
       " 'appeal',\n",
       " 'show',\n",
       " 'due',\n",
       " 'fact',\n",
       " 'goes',\n",
       " 'shows',\n",
       " 'would',\n",
       " \"n't\",\n",
       " 'dare',\n",
       " 'Forget',\n",
       " 'pretty',\n",
       " 'pictures',\n",
       " 'painted',\n",
       " 'mainstream',\n",
       " 'audiences',\n",
       " 'forget',\n",
       " 'charm',\n",
       " 'forget',\n",
       " 'romance',\n",
       " '...',\n",
       " 'OZ',\n",
       " \"n't\",\n",
       " 'mess',\n",
       " 'around',\n",
       " 'first',\n",
       " 'episode',\n",
       " 'ever',\n",
       " 'saw',\n",
       " 'struck',\n",
       " 'nasty',\n",
       " 'surreal',\n",
       " 'could',\n",
       " \"n't\",\n",
       " 'say',\n",
       " 'ready',\n",
       " 'watched',\n",
       " 'developed',\n",
       " 'taste',\n",
       " 'Oz',\n",
       " 'got',\n",
       " 'accustomed',\n",
       " 'high',\n",
       " 'levels',\n",
       " 'graphic',\n",
       " 'violence',\n",
       " 'violence',\n",
       " 'injustice',\n",
       " 'crooked',\n",
       " 'guards',\n",
       " \"'ll\",\n",
       " 'sold',\n",
       " 'nickel',\n",
       " 'inmates',\n",
       " \"'ll\",\n",
       " 'kill',\n",
       " 'order',\n",
       " 'get',\n",
       " 'away',\n",
       " 'well',\n",
       " 'mannered',\n",
       " 'middle',\n",
       " 'class',\n",
       " 'inmates',\n",
       " 'turned',\n",
       " 'prison',\n",
       " 'bitches',\n",
       " 'due',\n",
       " 'lack',\n",
       " 'street',\n",
       " 'skills',\n",
       " 'prison',\n",
       " 'experience',\n",
       " 'Watching',\n",
       " 'Oz',\n",
       " 'may',\n",
       " 'become',\n",
       " 'comfortable',\n",
       " 'uncomfortable',\n",
       " 'viewing',\n",
       " '....',\n",
       " 'thats',\n",
       " 'get',\n",
       " 'touch',\n",
       " 'darker',\n",
       " 'side']"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb['review'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing Special Charcaters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        One reviewers mentioned watching Oz episode ll...\n",
       "1        wonderful little production filming technique ...\n",
       "2        thought wonderful way spend time hot summer we...\n",
       "3        Basically s family little boy Jake thinks s zo...\n",
       "4        Petter Mattei s  Love Time Money  visually stu...\n",
       "                               ...                        \n",
       "49995    thought movie right good job nt creative origi...\n",
       "49996    Bad plot bad dialogue bad acting idiotic direc...\n",
       "49997    Catholic taught parochial elementary schools n...\n",
       "49998    m going disagree previous comment side Maltin ...\n",
       "49999    one expects Star Trek movies high art fans exp...\n",
       "Name: review, Length: 50000, dtype: object"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_special_characters(text, remove_digits = False):\n",
    "    pattern = r'[^a-zA-Z0-9\\s]' if not remove_digits else r'[a-zA-Z\\s]'\n",
    "    text = re.sub(pattern, '', text)\n",
    "    return text\n",
    "\n",
    "imdb['review'] = imdb['review'].astype(str).apply(remove_special_characters) \n",
    "imdb['review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'One reviewers mentioned watching Oz episode ll hooked right exactly happened meThe first thing struck Oz brutality unflinching scenes violence set right word GO Trust show faint hearted timid show pulls punches regards drugs sex violence hardcore classic use wordIt called OZ nickname given Oswald Maximum Security State Penitentary focuses mainly Emerald City experimental section prison cells glass fronts face inwards privacy high agenda Em City home many  Aryans Muslims gangstas Latinos Christians Italians Irish  scuffles death stares dodgy dealings shady agreements never far awayI would say main appeal show due fact goes shows would nt dare Forget pretty pictures painted mainstream audiences forget charm forget romance  OZ nt mess around first episode ever saw struck nasty surreal could nt say ready watched developed taste Oz got accustomed high levels graphic violence violence injustice crooked guards ll sold nickel inmates ll kill order get away well mannered middle class inmates turned prison bitches due lack street skills prison experience Watching Oz may become comfortable uncomfortable viewing  thats get touch darker side'"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb['review'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIMIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review\n",
       "False    50000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from nltk.corpus import stopwords\n",
    "# from nltk.tokenize import word_tokenize\n",
    "\n",
    "# # # Some stuff we have to download\n",
    "# # nltk.download('punkt')\n",
    "# # nltk.download('stopwords')\n",
    "\n",
    "# # Getting English stop words from nltk\n",
    "# stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# tokenizer = ToktokTokenizer()\n",
    "\n",
    "# # Removing the stopwords\n",
    "# def remove_stopwords(text):\n",
    "#     tokens = tokenizer.tokenize(text)\n",
    "#     tokens = [token.strip() for token in tokens]\n",
    "#     filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "#     filtered_text = ' '.join(filtered_tokens)\n",
    "#     return filtered_text\n",
    "\n",
    "# # Applying our function:\n",
    "# imdb['review'] = imdb['review'].apply(remove_stopwords)\n",
    "\n",
    "# # Performing a sanity check:\n",
    "# sanity_check = imdb['review'].isin(stop_words)\n",
    "# sanity_check.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see our entries no longer have stop words in them but we can see that they are littered with html tags, so let's go ahead and take those out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing Special Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Stemming:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(min_df= 0, max_df= 1, binary= False, ngram_range= (1,3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
